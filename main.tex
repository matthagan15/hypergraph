\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath,amsthm, amssymb}
\usepackage{mathrsfs}
% \usepackage[margin=1in]{geometry}
\usepackage{mathtools}
\usepackage{dsfont}
\usepackage{xcolor}
\usepackage{xfrac}
\usepackage{algorithm,algpseudocode}
\usepackage{todonotes}
\usepackage{qcircuit}
\usepackage{smartref}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{topaths,calc}



%%%%%%%%    NOTATION DEFINITIONS FOR EASIER WRITING
\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle #1|}
\newcommand{\braket}[2]{\langle #1|#2\rangle}
\newcommand{\ketbra}[2]{| #1\rangle\! \langle #2|}
\newcommand{\parens}[1]{\left( #1 \right)}
\newcommand{\brackets}[1]{\left[ #1 \right]}
\newcommand{\norm}[1]{\left| \left| #1 \right| \right|}
\newcommand{\diamondnorm}[1]{\left| \left| #1 \right| \right|_\diamond}
\newcommand{\anglebrackets}[1]{\left< #1 \right>}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\openone}{\mathds{1}}
\newcommand{\expect}[1]{\mathbb{E}\brackets{#1}}
\newcommand{\prob}[1]{\text{Pr}\left[ #1 \right]}
\newcommand{\textprob}[1]{\text{Pr}\left[ \text{#1} \right]}
\newcommand{\bigo}[1]{\mathcal{O}\left( #1 \right)}
\newcommand{\bigotilde}[1]{\widetilde{\mathcal{O}} \left( #1 \right)}
\newcommand{\ts}{\textsuperscript}
\newcommand{\field}{\mathbb{F}}


%%%%%%%%    VARIABLE DEFINITIONS FOR EASY CHANGING LATER
\newcommand{\calX}{\mathcal{X}}
\newcommand{\calY}{\mathcal{Y}}
\newcommand{\calZ}{\mathcal{Z}}

\newcommand{\ChanGUE}{\mathcal{T}_{GUE}}
\newcommand{\ChanHaar}{\mathcal{T}_{Haar}}

%%%%%%%%    OPERATOR DEFINITIONS FOR EASIER MATHS
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\card}{card}
\newcommand{\cardi}[1]{\card \parens{ #1 }}
\newcommand{\trace}[1]{\Tr \brackets{ #1 }}
\newcommand{\partrace}[2]{\Tr_{#1} \parens{ #2 }}

\newcommand{\complex}{\mathbb{C}}
\newcommand{\matn}{\mathbb{M}_n}
% \newcommand{\identity}{\mathbbm{1}}
\newcommand{\identity}{\mathds{1}}
\newcommand{\ident}{\mathbb{I}}
\newcommand{\hilbspace}{\mathscr{H}}
\newcommand{\partfun}{\mathcal{Z}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{defn}{Definition}
% \DeclareMathOperator*{\dim}{dim}

\newcommand\disjointUnion{\rotatebox[origin=c]{180}{$\prod$}}

\title{Properties of Hypergraphs}
\author{Matthew Hagan}
\date{\today}

\begin{document}



\maketitle
\begin{abstract}
	We propose new definitions that allow for the study of spectral properties of hypergraphs. We first study the vector spaces that directed, weighted hypergraphs act on as linear opertors. We then study the differences between the complete hypergraph as compared to a complete graph representation and show how this leads to a quantity we denote $\card(.)$.
    We give a simple algorithm to output an estimate of $\card(H)$ for a hypergraph $H$ that satisfies a PAC-style bound.
\end{abstract}
% \tableofcontents

\section{Introduction}
Hypergraphs are generally viewed as a generalization of graphs, so we first need to define graphs. A graph $G$ is typically viewed as two sets $G = (N, E)$, one set $N = \set{n_i}_{i=1}^n$ of nodes ($V$ is reserved for vector spaces later) and one set of edges $E = \set{(n_a, n_b, w_{a,b})}$, where $n_a$ represents the head node and $n_b$ the tail, if this edge is directed, and $w_{a,b} \in \field$ the weight. The field $\field$ is left arbitrary for now, all we require is that the edge weights be in a field so we can construct vector spaces later.

We primarily focus on directed, weighted hypergraphs $H$ in which we take a node set $N$ and construct a set of hyperedges, also denoted $E$ as in the case for graphs, where a single hyperedge is defined as $e = (\alpha_e \subseteq N, \beta_e \subseteq N, w_e)$, which is the same as for graphs except that the head and tail are now subsets of $N$ as opposed to single elements. We will use $\alpha(e)$ to denote the head/input subset of a hyperedge and $\beta(e)$ to denote the tail/output subset. 

One of the most useful areas of graph theory research has been the viewpoint that graphs can be represented as linear operators on an associated vector space. This vector space is straightforwardly constructed by assigning a single basis element to each element $n_i \in N$, for simplicity we use Dirac notation to indicate vectors $\ket{n_i}$ as opposed to arrows $\vec{n_i}$. Note that a ket may not be a normalized quantum state, but any arbitrary vector. Studying the properties of linear operators related to graphs is called spectral graph theory, and has led to many important findings of theoretic and practical significance. 

To study linear operators related to hypergraphs we will need to construct a slightly more intricate vector space. To start, we note the following useful property of the power set 
\begin{equation}
    2^N =  \bigcup_{k=0}^{|N|} N_k = \bigoplus_{k=0}^{k = |N|} N_k,
\end{equation}
where $N_k := \set{X \subseteq N : |X| = k}$ is the set of subsets of $N$ of cardinality $k$ and we use $\bigoplus$ to denote the disjoint union, or coproduct, when working in the category Set. Given this set $2^N$ we can now construct a new vector space by simply assigning each element $s_i \in 2^N$ a basis vector $\ket{s_i}$. We use $s_i$ to denote a single indexed subset of $N$. 

\begin{defn}[Hyperspace]
    Let $F$ denote the free module action and $N = \set{n_i}_{i=1}^n$. We call the vector space $V = \bigoplus_{k=0}^n V_k = F(2^N) = F(\bigoplus_{k=0}^n N_k) = \bigoplus_{k=0}^n F(N_k)$ associated with a hypergraph the associated hyperspace. A hyperspace $V$ comes with projectors $\Pi_k : V \to V_k$ and inclusions $\eta_k : V_k \to V$. We denote the natural basis $\ket{s_i}$, where each $s_i \subset N$ is an indexed subset of $N$ the subset basis of the hyperspace. This basis allows for a function $\cardi{\ket{\set{n_1}}} = 1$ which gives the cardinality of the underlying set. We denote the useful combination $\widetilde{\Pi}_k = \eta \circ \Pi_k : V \to V$ which acts as
    \begin{equation}
        \widetilde{\Pi_k} \ket{s_i} = \begin{cases}
            0 & \text{if } s_i \notin N_k \\
            \ket{s_i} & \text{if } s_i \in N_k 
        \end{cases}
    \end{equation}
\end{defn}

We now can define the adjacency matrix for the hypergraph
\begin{equation}
    A_H = \sum_{i=1}^{2^n} \sum_{j=1}^{2^n} w_{i,j} \ketbra{s_i}{s_j},
\end{equation}
which is very standard (is that even useful?). We can study probabilistic processes or quantum systems modeled by hypergraphs by restricting our attention to isometric adjacency matrices, either $L_1, L_2, \ldots$. 
Similarly a laplacian $L_H = D - A$, where $D$ is the "degree" of each basis vector defined in the usual graph theoretic sense, is straightforward to define and is a positive semi-definite operator. 

Now that we have seen how hypergraphs can be represented as adjacency matrices on an exponentially larger space, we are led to the following question: If matrices can be represented as weighted directed graphs, what is the difference between a hypergraph on a set of size $n$ and a weighted, directed graph on a space of size $2^n$? To isolate the differences we will utilize the complete hypergraph on $N$ and a complete graph on $2^N$, without the knowledge that the set $2^N$ is a power set. 

Let $H_C$ denote the complete hypergraph and $G_C$ the respective complete graph. To isolate differences we will use the concept of cardinality of the basis vectors. Define the random variable $\card(.)$ as follows
\begin{align}
    \card(\ket{\set{}}) &= 0 \\
    \card(\ket{\set{n_1}}) &= 1 \\
    \expect{\cardi{\frac{1}{2} \ket{\set{n_1, n_2}} + \frac{1}{2} \ket{\set{}} }} &= 1 \\
    \prob{\cardi{\sum_{i} c_i \ket{s_i}} = k } & \coloneqq \frac{\sum_{i,j} c_i \bra{s_j} \Pi_k \ket{s_i}}{ \sum_i c_i}.
\end{align}
We now look at the complete graph and hypergraphs. Let $\ket{e} = \frac{1}{\sqrt{2^n}} \sum_{i=1}^{2^n} \ket{s_i}$ denote the $L_2$ normalized all ones vector in the subset basis. The walk operator, or adjacency operator, for the complete hypergraph is then simply $H_C = \ketbra{e}{e}$, or the all ones matrix properly normalized. As a hypergraph we have access to the $\card$ operator, which allows us to compute the cardinality distribution of the dominant eigenvector of $H_C$ as
\begin{align}
    \cardi{H, k} := \prob{\cardi{\ket{e}} = k } = \frac{\binom{n}{k}}{2^n}.
\end{align}
We can generalize this notion to an arbitrary stochastic hypergraph $H$  by replacing $\ket{e} \mapsto \lim_{m \to \infty} \int H^m \ket{\psi} ~d\ket{\psi} $, which is simply a method of obtaining the dominant eigenvectors.

For the complete hypergraph we note that we can easily compute quantities such as the expected cardinality and the entropy
\begin{align}
    \expect{\cardi{H, k}} &= \frac{n}{2} \\
    \mathbf{H} \brackets{\cardi{H, k}} &= \\
\end{align}





\begin{figure}
    \begin{tikzpicture}
        \node (n1) at (0,0) {};
        \node (n2) at (1,1) {};
        \node (n3) at (2,0) {};
        \node (n4) at (3, 3) {};
        \node (n5) at (4, 2) {};
        \foreach \v in {1,2,3,4,5} {
            \fill (n\v) circle (0.1);
        }
    \end{tikzpicture}
    \caption[Hypergraph]{An example of a directed, weighted hypergraph with a single edge $e$}
\end{figure}



\section{Algebraic Construction}
Now that we have a vector space, we can define a hyperedge $e$ simply as a linear map on this overall vector space, or in other words as a $\field$-module endomorphism
\begin{equation}
    e \in \Hom_{\field} (V, V).
\end{equation}
This condition of linearity is per usual. We say $e$ is a $\field$-module homomorphism (aka linear map) if for all scalars $c \in \field$ and vectors $u, v \in V$
\begin{align}
    e(c * v) = c * e(v) \\
    e (u + v) = e(u) + e(v).
\end{align}
Note that we can add elements of $V$ due to the underlying abelian group structure of the module. 

We then take another step and ask the question, can we induce a module structure on the set of linear maps $\Hom_{\field}$? Since $\field$ is a field we are allowed to do so (we only really need commutativity of $\field$ ). First define the action of $c \in \field$ on $e \in \Hom_\field(V, V)$ in the obvious way $(c * e) (v) := c * e(v)$. This may seem like simply removing the parenthesis, but the question of linearity shows it is a different matter:
\begin{align}
    (c * e) (s * v) &= c * e( s * v) \\
    &= (c * s) * e(v) \\
    &\overset{!}{=} s * (c * e) (v),
\end{align}
where the ! means we used commutativity to get $(c *e) (s * v) = s * (c * e) (v)$. Addition follows straightforwardly, $(e+f) (v) \coloneqq e(v) + f(v)$. This all may seem redundant, but it's important to spell out that everything is legal.

So we now have hyperedges defined as a specific linear map $e$ acting on a vector space $V$, and that we can add hyperedges and multiply them by some field. We then can simply define a hypergraph $h = \sum c_i e_i$, a weighted sum of hyperedges. Thats it! 


\section{Preliminaries}
\begin{itemize}
    \item Modules
    \item Free Modules
    \item Coproducts
    \item 
\end{itemize}
\section{Construction of a unique Linear Map}
\subsection{Formal Definition}
\subsection{Informal Discussion}

\section{Applications}
\subsection{Two State Discrete Time Quantum Systems}
\subsection{epidemiology}
\subsection{MIMO}
\subsection{local-to-global}

\section{Discussion}
A linear theory of hypergraph connections allows for immediate generalizations of many previous concepts. We posit a few conjectured areas that could lead to fruitful future research.
\begin{itemize}
    \item There is a beautiful theorem by Sunada that states that a graph $G$ is an optimal expander, aka the graph is Ramanujan, if and only if it's Ihara zeta function satisfies a Graph variant of the Riemann Hypothesis. Our theory now allows for these questions to be generalized to the hypergraph setting.
    \item One can impose that a hypergraph maintains the global vector given a certain norm, for example an $L_1$ normalized theory would consitute a model that conserves probability. If one defines a parametrization of the probability of each of these edges how does an observed data point update these models? Algorithms that could efficiently perform updates of all models seems unlikely, but what constrictions could lead to efficient bayesian updates?
    \item Previous definitions of hypergraphs have noted a duality between nodes and edges, as in there is a one-to-one mapping between a graph with edge sets and vertex sets swapped in a well defined manner. How does this duality affect the spectral properties of the hypergraph connections?
    \item Neural Networks are constructed by creating a set of nodes, assigning each a number, and then imposing a directed graph structure with weighted edges from each layer to the next. This theory allows for a linear version of a neural network that connects multiple nodes in one layer to multiple nodes in the next while retaining single node connections.
    \item A common thread in modern algorithms is the ability to compute global properties of an object from local information. For example the PCP theorem states that a computational proof can be verified with high probability by only accessing a constant number of bits from the proof. Conceptually a global property of a string of bits can be verified through only local information. How can one define local and global properties on hypergraphs?
    \item  A current area of study known as Topological Data Analysis (TDA) attempts to study topological properties of an underlying manifold $X$ via a collection of 0 dimensional samples (aka points in $\mathbb{R}^n$). These points are then used to construct a graph via the usual Euclidean metric on
    \item Graphs induce a unique linear hypergraph via the action of powering. For example specifically look at edges in the space $V_2$.  
\end{itemize}

\section*{Acknowledgements}

how could this give a proof of compiler correctness?

what would a hypergraph binary tree look like?

\end{document}
