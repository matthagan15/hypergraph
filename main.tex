\documentclass{article}
\usepackage[utf8]{inputenc}

\usepackage{amsmath,amsthm, amssymb}
\usepackage{mathrsfs}
% \usepackage[margin=1in]{geometry}
\usepackage{mathtools}
\usepackage{dsfont}
\usepackage{xcolor}
\usepackage{xfrac}
\usepackage{algorithm,algpseudocode}
\usepackage{todonotes}
\usepackage{qcircuit}
\usepackage{smartref}
\usepackage{graphicx}



%%%%%%%%    NOTATION DEFINITIONS FOR EASIER WRITING
\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle #1|}
\newcommand{\braket}[2]{\langle #1|#2\rangle}
\newcommand{\ketbra}[2]{| #1\rangle\! \langle #2|}
\newcommand{\parens}[1]{\left( #1 \right)}
\newcommand{\brackets}[1]{\left[ #1 \right]}
\newcommand{\norm}[1]{\left| \left| #1 \right| \right|}
\newcommand{\diamondnorm}[1]{\left| \left| #1 \right| \right|_\diamond}
\newcommand{\anglebrackets}[1]{\left< #1 \right>}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\openone}{\mathds{1}}
\newcommand{\expect}[1]{\mathbb{E}\brackets{#1}}
\newcommand{\prob}[1]{\text{Pr}\left[ #1 \right]}
\newcommand{\textprob}[1]{\text{Pr}\left[ \text{#1} \right]}
\newcommand{\bigo}[1]{\mathcal{O}\left( #1 \right)}
\newcommand{\bigotilde}[1]{\widetilde{\mathcal{O}} \left( #1 \right)}
\newcommand{\ts}{\textsuperscript}
\newcommand{\field}{\mathbb{F}}


%%%%%%%%    VARIABLE DEFINITIONS FOR EASY CHANGING LATER
\newcommand{\calX}{\mathcal{X}}
\newcommand{\calY}{\mathcal{Y}}
\newcommand{\calZ}{\mathcal{Z}}

\newcommand{\ChanGUE}{\mathcal{T}_{GUE}}
\newcommand{\ChanHaar}{\mathcal{T}_{Haar}}

%%%%%%%%    OPERATOR DEFINITIONS FOR EASIER MATHS
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\Hom}{Hom}
\newcommand{\trace}[1]{\Tr \brackets{ #1 }}
\newcommand{\partrace}[2]{\Tr_{#1} \parens{ #2 }}

\newcommand{\complex}{\mathbb{C}}
\newcommand{\matn}{\mathbb{M}_n}
% \newcommand{\identity}{\mathbbm{1}}
\newcommand{\identity}{\mathds{1}}
\newcommand{\ident}{\mathbb{I}}
\newcommand{\hilbspace}{\mathscr{H}}
\newcommand{\partfun}{\mathcal{Z}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}{Definition}
% \DeclareMathOperator*{\dim}{dim}

\newcommand\disjointUnion{\rotatebox[origin=c]{180}{$\prod$}}

\title{Simplified Hypergraph Cuts and Walks via a Spectral Hypergraph Theory}
\author{Matthew Hagan}
\date{\today}

\begin{document}



\maketitle
\begin{abstract}
	We propose a definition of hypergraphs that is amenable to clearly defined random walk processes and cuts resulting from higher-dimensional dynamics on $n$ nodes. By dimension, we are referring to the number of nodes that a dynamical process can act on at once. A standard linear process acts on 1-dimensional objects but 2-dimensional or arbitrary $k$-dimensional (up to $k=n$) dynamics are permissable. To illustrate the utility of this viewpoint of hypergraph dynamics we study the spectral properties resulting from cuts and random processes.
\end{abstract}
\tableofcontents

\section{Introduction}

Hypergraphs start with a notion of a set of nodes $N = \set{n_1, n_2, \ldots, n_m}$ and it's power set $2^N = \set{ \set{}, \set{n_i}, \set{n_i, n_j | n_i \neq n_j}, \ldots }$. It will serve useful to divide subsets of $N$ by the number of elements they contain, so let $N_k = \set{x_1, x_2, \ldots x_k : x_i \neq x_j \forall i,j ; x_i \in N \forall i}$. A useful fact of power sets is that they can be decomposed as the disjoint union of sets:
\begin{equation}
    2^N = \disjointUnion_{k = 0}^{|N|} N_k = \bigoplus_{k=0}^{k = |N|} N_k = \bigcup_{k=0}^{|N|} N_k,
\end{equation}
where we can view the disjoint union as the coproduct construction in the category of sets.

Our goal is to turn $2^N$ into a vector space. We do this by first considering a field $\field_N$ and then taking it's free module (free vector space?). Let $V$ be the free module of $2^N$ and $V_k$ the free module of $N_k$. 
\begin{claim}
\begin{equation}
        V = \bigoplus_{k=0}^{|N|} V_k.
\end{equation}
\end{claim}
The proof of this claim isn't really done. This construction is nice as it automatically gives us for free the inclusion maps $i_k : V_k \to V$ and projectors $\Pi_k : V \to V_k$ due to the fact that coproducts and products coincide in the category of $\field$-modules. $V$ being a vector space means we can take elements of the field $c \in \field$ 

Now that we have a vector space, we can define a hyperedge $e$ simply as a linear map on this overall vector space, or in other words as a $\field$-module endomorphism
\begin{equation}
    e \in \Hom_{\field} (V, V).
\end{equation}
This condition of linearity is per usual. We say $e$ is a $\field$-module homomorphism (aka linear map) if for all scalars $c \in \field$ and vectors $u, v \in V$
\begin{align}
    e(c * v) = c * e(v) \\
    e (u + v) = e(u) + e(v).
\end{align}
Note that we can add elements of $V$ due to the underlying abelian group structure of the module. 

We then take another step and ask the question, can we induce a module structure on the set of linear maps $\Hom_{\field}$? Since $\field$ is a field we are allowed to do so (we only really need commutativity of $\field$ ). First define the action of $c \in \field$ on $e \in \Hom_\field(V, V)$ in the obvious way $(c * e) (v) := c * e(v)$. This may seem like simply removing the parenthesis, but the question of linearity shows it is a different matter:
\begin{align}
    (c * e) (s * v) &= c * e( s * v) \\
    &= (c * s) * e(v) \\
    &\overset{!}{=} s * (c * e) (v),
\end{align}
where the ! means we used commutativity to get $(c *e) (s * v) = s * (c * e) (v)$. Addition follows straightforwardly, $(e+f) (v) \coloneqq e(v) + f(v)$. This all may seem redundant, but it's important to spell out that everything is legal.

So we now have hyperedges defined as a specific linear map $e$ acting on a vector space $V$, and that we can add hyperedges and multiply them by some field. We then can simply define a hypergraph $h = \sum c_i e_i$, a weighted sum of hyperedges. Thats it! 


\section{Preliminaries}
\begin{itemize}
    \item Modules
    \item Free Modules
    \item Coproducts
    \item 
\end{itemize}
\section{Construction of a unique Linear Map}
\subsection{Formal Definition}
\subsection{Informal Discussion}

\section{Applications}
\subsection{Two State Discrete Time Quantum Systems}
\subsection{epidemiology}
\subsection{MIMO}
\subsection{local-to-global}

\section{Discussion}
A linear theory of hypergraph connections allows for immediate generalizations of many previous concepts. We posit a few conjectured areas that could lead to fruitful future research.
\begin{itemize}
    \item There is a beautiful theorem by Sunada that states that a graph $G$ is an optimal expander, aka the graph is Ramanujan, if and only if it's Ihara zeta function satisfies a Graph variant of the Riemann Hypothesis. Our theory now allows for these questions to be generalized to the hypergraph setting.
    \item One can impose that a hypergraph maintains the global vector given a certain norm, for example an $L_1$ normalized theory would consitute a model that conserves probability. If one defines a parametrization of the probability of each of these edges how does an observed data point update these models? Algorithms that could efficiently perform updates of all models seems unlikely, but what constrictions could lead to efficient bayesian updates?
    \item Previous definitions of hypergraphs have noted a duality between nodes and edges, as in there is a one-to-one mapping between a graph with edge sets and vertex sets swapped in a well defined manner. How does this duality affect the spectral properties of the hypergraph connections?
    \item Neural Networks are constructed by creating a set of nodes, assigning each a number, and then imposing a directed graph structure with weighted edges from each layer to the next. This theory allows for a linear version of a neural network that connects multiple nodes in one layer to multiple nodes in the next while retaining single node connections.
    \item A common thread in modern algorithms is the ability to compute global properties of an object from local information. For example the PCP theorem states that a computational proof can be verified with high probability by only accessing a constant number of bits from the proof. Conceptually a global property of a string of bits can be verified through only local information. How can one define local and global properties on hypergraphs?
    \item  A current area of study known as Topological Data Analysis (TDA) attempts to study topological properties of an underlying manifold $X$ via a collection of 0 dimensional samples (aka points in $\mathbb{R}^n$). These points are then used to construct a graph via the usual Euclidean metric on
    \item Graphs induce a unique linear hypergraph via the action of powering. For example specifically look at edges in the space $V_2$.  
\end{itemize}

\section*{Acknowledgements}

how could this give a proof of compiler correctness?

what would a hypergraph binary tree look like?

\end{document}
